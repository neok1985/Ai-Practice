{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN(강사님버전).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nEeYce_1d6ZL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')     # 한글 폰트\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', unicode_minus=False)           # 유니코드 \"-\" sign\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.datasets import reuters\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global constants and hyper-parameters\n",
        "MY_SAMPLE = 2947\n",
        "NUM_CLASS = 46          # Classification class\n",
        "MY_NUM_WORDS = 2000     # number of words in dictionary\n",
        "\n",
        "\n",
        "MY_HIDDEN = 512         # \n",
        "MY_DROPOUT = 0.5        # Dropout rate : temporarily dropout given rate of cell's outputs to \"0\" : like Regularization\n",
        "\n",
        "MY_EPOCH = 10\n",
        "MY_BATCH = 64"
      ],
      "metadata": {
        "id": "RJN1me4mekT-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
        "          'housing','money-supply','coffee','sugar','trade','reserves', \n",
        "          'ship','cotton','carcass','crude','nat-gas','cpi','money-fx',\n",
        "          'interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "          'strategic-metal','livestock','retail','ipi','iron-steel',\n",
        "          'rubber','heat','jobs','lei','bop','zinc','orange',\n",
        "          'pet- chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "metadata": {
        "id": "qr7h9y6Meqed"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_shape():\n",
        "  print('\\n== DB SHAPE INFO ==')\n",
        "  print('X_train shape = ', X_train.shape)\n",
        "  print('X_test shape = ', X_test.shape)\n",
        "  print('Y_train shape = ', Y_train.shape)\n",
        "  print('Y_test shape = ', Y_test.shape) \n",
        "  print()"
      ],
      "metadata": {
        "id": "ZM7PUqX5erOk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = MY_NUM_WORDS, test_split = 0.3)\n",
        "\n",
        "show_shape()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z5UbVGOe3U1",
        "outputId": "5d67dfa1-b023-4179-e433-9d9606a6e441"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859,)\n",
            "X_test shape =  (3369,)\n",
            "Y_train shape =  (7859,)\n",
            "Y_test shape =  (3369,)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# statistics on how many articles per category in the train DB\n",
        "# numpy unique is useful in this case\n",
        "print('\\n== TRAIN DATA CONTENT INFO ==')\n",
        "unique, counts = np.unique(Y_train, return_counts = True)\n",
        "for i in range(len(unique)):\n",
        "  print(unique[i], labels[i], \"=\", counts[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtVr2_iye5Gt",
        "outputId": "6f429566-ed15-4443-8e9a-f43aede3c5ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== TRAIN DATA CONTENT INFO ==\n",
            "0 cocoa = 50\n",
            "1 grain = 378\n",
            "2 veg-oil = 66\n",
            "3 earn = 2769\n",
            "4 acq = 1701\n",
            "5 wheat = 14\n",
            "6 copper = 39\n",
            "7 housing = 15\n",
            "8 money-supply = 126\n",
            "9 coffee = 93\n",
            "10 sugar = 114\n",
            "11 trade = 337\n",
            "12 reserves = 40\n",
            "13 ship = 149\n",
            "14 cotton = 18\n",
            "15 carcass = 19\n",
            "16 crude = 387\n",
            "17 nat-gas = 33\n",
            "18 cpi = 59\n",
            "19 money-fx = 475\n",
            "20 interest = 238\n",
            "21 gnp = 91\n",
            "22 meal-feed = 10\n",
            "23 alum = 36\n",
            "24 oilseed = 56\n",
            "25 gold = 77\n",
            "26 tin = 18\n",
            "27 strategic-metal = 13\n",
            "28 livestock = 43\n",
            "29 retail = 19\n",
            "30 ipi = 38\n",
            "31 iron-steel = 34\n",
            "32 rubber = 30\n",
            "33 heat = 9\n",
            "34 jobs = 43\n",
            "35 lei = 10\n",
            "36 bop = 46\n",
            "37 zinc = 17\n",
            "38 orange = 16\n",
            "39 pet- chem = 20\n",
            "40 dlr = 32\n",
            "41 gas = 28\n",
            "42 silver = 10\n",
            "43 wpi = 19\n",
            "44 hog = 10\n",
            "45 lead = 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample data in its raw format\n",
        "print('\\n== SAMPLE ARTICLE (RAW) ==')\n",
        "print(\"article #\", MY_SAMPLE)\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])\n",
        "print(\"number of words\", len(X_train[MY_SAMPLE]))\n",
        "print(X_train[MY_SAMPLE])\n",
        "\n",
        "# python dictionary: word -> index\n",
        "# zero index is not used\n",
        "word_to_id = reuters.get_word_index()\n",
        "print('\\n== DICTIONARY INFO ==')\n",
        "print(\"There are\", len(word_to_id) + 1, \"words in the dictionary.\")\n",
        "print('The index of \"the\" is', word_to_id['the'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fm3BHhpgAJU",
        "outputId": "3daa9f6e-cf79-4738-d7ea-e8a40c71f99d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (RAW) ==\n",
            "article # 2947\n",
            "category 4 acq\n",
            "number of words 61\n",
            "[1, 2, 1229, 81, 8, 16, 515, 25, 270, 5, 4, 2, 1229, 111, 267, 7, 73, 2, 2, 7, 108, 13, 80, 1448, 28, 365, 12, 11, 15, 1986, 2, 69, 158, 18, 1296, 1275, 7, 2, 1627, 2, 2, 4, 393, 374, 1229, 323, 5, 2, 1229, 7, 2, 9, 25, 2, 473, 936, 4, 49, 8, 17, 12]\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n",
            "\n",
            "== DICTIONARY INFO ==\n",
            "There are 30980 words in the dictionary.\n",
            "The index of \"the\" is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python dictionary: index -> word\n",
        "# this is the opposite to word_to_id dictionary\n",
        "id_to_word = {}\n",
        "for key, value in word_to_id.items():\n",
        "  id_to_word[value] = key"
      ],
      "metadata": {
        "id": "um8QQxjgfNzf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoding():\n",
        "  decoded = []\n",
        "  for i in X_train[MY_SAMPLE]:\n",
        "    word = id_to_word.get(i - 3, \"???\")\n",
        "    decoded.append(word)\n",
        "\n",
        "  print('\\n== SAMPLE ARTICLE (DECODED) ==')\n",
        "  print(\" \".join(decoded))\n",
        "  \n",
        "decoding()\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K_mI9gef0fV",
        "outputId": "111d3e5c-e899-46a0-e65a-b8f1f9566f2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (DECODED) ==\n",
            "??? ??? telephone corp said it completed its acquisition of the ??? telephone co based in new ??? ??? in exchange for stock valued at 26 3 mln dlrs enterprises ??? about 16 000 access lines in ??? county ??? ??? the third operating telephone subsidiary of ??? telephone in ??? and its ??? largest overall the company said reuter 3\n",
            "category 4 acq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will NOT do padding (as in movie review classification)\n",
        "# instead we will do tokenization for the inputs\n",
        "# we get a numpy array of size MY_NUM_WORDS for each input \n",
        "# the entries are integer counts \n",
        "# the resulting matrix is very big\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# for i in range(10):\n",
        "#   print(len(X_train[i]))\n",
        "\n",
        "Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "\n",
        "print('before:', X_train[0])\n",
        "print('number before:', len(X_train[0]))\n",
        "X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "print('after:', X_train[0])\n",
        "print('number after:', len(X_train[0]))\n",
        "\n",
        "X_test = Tok.sequences_to_matrix(X_test, mode = 'count')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XWIhuXojLjv",
        "outputId": "eb7077b3-9e61-4f2d-c479-9ba44bc820d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "number before: 87\n",
            "after: [0. 1. 4. ... 0. 0. 0.]\n",
            "number after: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "# X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "# X_test = Tok.sequences_to_matrix(X_test, mode = 'count’)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (TOKENIZED INPUT) ==')\n",
        "sample = X_train[MY_SAMPLE]\n",
        "print(*sample, sep = ' ')\n",
        "print(\"Array size:\", len(sample))\n",
        "print(\"Sum of entries:\", np.sum(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5fhJWwPjSy5",
        "outputId": "b9444840-5d3e-489e-8295-a52b462b9cb4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (TOKENIZED INPUT) ==\n",
            "0.0 1.0 11.0 0.0 3.0 2.0 0.0 4.0 2.0 1.0 0.0 1.0 2.0 1.0 0.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "Array size: 2000\n",
            "Sum of entries: 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output reshaping using one-hot encoding\n",
        "# from keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train, NUM_CLASS)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASS)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==')\n",
        "sample = Y_train[MY_SAMPLE]\n",
        "print(sample)\n",
        "print(\"Array size:\", len(sample))\n",
        "\n",
        "show_shape()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag4EkQg7jjzs",
        "outputId": "5968e994-950f-4370-c5c7-26db5e4931f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Array size: 46\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859, 2000)\n",
            "X_test shape =  (3369, 2000)\n",
            "Y_train shape =  (7859, 46)\n",
            "Y_test shape =  (3369, 46)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "# MODEL BUILDING AND TRAINING #\n",
        "###############################\n",
        "# build a keras sequential model of our DNN\n",
        "# softmax is needed for multi-class classification\n",
        "model = Sequential()\n",
        "model.add(Dense(units=MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))\n",
        "# model.add(Dense(MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))  => have to give Tuple, eg (MY_NUM_WORDS,)\n",
        "model.add(Activation('relu'))       # later comment this out or use others, \n",
        "model.add(Dropout(MY_DROPOUT))\n",
        "model.add(Dense(NUM_CLASS))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ao0tGA2jxI8",
        "outputId": "dba14358-12a4-449e-95aa-45dd3b04423f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               1024512   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 46)                23598     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 46)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,048,110\n",
            "Trainable params: 1,048,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction using the model\n",
        "# shape needs to change from (2000,) to (1, 2000)\n",
        "def ask_question():\n",
        "  sample = X_train[MY_SAMPLE]\n",
        "  sample = sample.reshape(1, sample.shape[0])\n",
        "  pred = model.predict(sample, verbose = 0)\n",
        "  guess = np.argmax(pred)\n",
        "  answer = np.argmax(Y_train[MY_SAMPLE])\n",
        "  \n",
        "  print('\\n== SAMPLE QUESTION ==')\n",
        "  print(\"My guess for sample article:\", guess, labels[guess])\n",
        "  print(\"The answer is:\", answer, labels[answer]) \n",
        "  print()\n",
        "\n",
        "ask_question()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LCemnWqkNM8",
        "outputId": "ab6a03e3-ed71-4e59-b8eb-eebf41452622"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE QUESTION ==\n",
            "My guess for sample article: 41 gas\n",
            "The answer is: 4 acq\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training and saving\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = MY_EPOCH, batch_size = MY_BATCH, verbose = 1)\n",
        "model.save('chap2.h5')"
      ],
      "metadata": {
        "id": "chgKGFg0kUtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# MODEL EVALUATION #\n",
        "####################\n",
        "# evaluate the model and calculate loss and accuracy\n",
        "score = model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "print('Prediction for the first news: ', pred[0])\n",
        "print(np.argmax(pred[0])) \n",
        "print('Answer: ', Y_test[0])\n",
        "print(labels[np.argmax(Y_test[0])]) \n",
        "\n",
        "\n",
        "# ask_question()"
      ],
      "metadata": {
        "id": "EhCD21WnkZDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}