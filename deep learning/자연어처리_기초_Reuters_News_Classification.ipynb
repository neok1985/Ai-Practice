{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어처리 기초 Reuters News Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "  !sudo apt-get install -y fonts-nanum\n",
        "  !sudo fc-cache -fv\n",
        "  !rm ~/.cache/matplotlib -rf\n",
        "\n",
        "  # 이 셀 실행후, 런타임 다시시작\n",
        "  "
      ],
      "metadata": {
        "id": "sfYcefdBp5Om",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dfc455-e6fa-4212-bd90-e93ca2fd420e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ou9Oma8wK93q"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic')     # 한글 폰트\n",
        "import matplotlib as mpl\n",
        "mpl.rc('axes', unicode_minus=False)           # 유니코드 \"-\" sign\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.datasets import reuters\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global constants and hyper-parameters\n",
        "MY_SAMPLE = 2947\n",
        "NUM_CLASS = 46          # Classification class\n",
        "MY_NUM_WORDS = 2000     # number of words in dictionary\n",
        "\n",
        "\n",
        "MY_HIDDEN = 512         # \n",
        "MY_DROPOUT = 0.5        # Dropout rate : temporarily dropout given rate of cell's outputs to \"0\" : like Regularization\n",
        "\n",
        "MY_EPOCH = 10\n",
        "MY_BATCH = 64"
      ],
      "metadata": {
        "id": "OKkyP9HFLXzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# DATABASE SETTING #\n",
        "####################\n",
        "# there are 46 news categories in reuters DB\n",
        "labels = ['cocoa','grain','veg-oil','earn','acq','wheat','copper',\n",
        "          'housing','money-supply','coffee','sugar','trade','reserves', \n",
        "          'ship','cotton','carcass','crude','nat-gas','cpi','money-fx',\n",
        "          'interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
        "          'strategic-metal','livestock','retail','ipi','iron-steel',\n",
        "          'rubber','heat','jobs','lei','bop','zinc','orange',\n",
        "          'pet- chem','dlr','gas','silver','wpi','hog','lead']"
      ],
      "metadata": {
        "id": "yMUJFzAsMF4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape information\n",
        "def show_shape():\n",
        "  print('\\n== DB SHAPE INFO ==')\n",
        "  print('X_train shape = ', X_train.shape)\n",
        "  print('X_test shape = ', X_test.shape)\n",
        "  print('Y_train shape = ', Y_train.shape)\n",
        "  print('Y_test shape = ', Y_test.shape) \n",
        "  print()"
      ],
      "metadata": {
        "id": "CQ88jndsMktS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the DB and print shape info\n",
        "(X_train, Y_train), (X_test, Y_test) = reuters.load_data(num_words = MY_NUM_WORDS, test_split = 0.3)\n",
        "\n",
        "show_shape()"
      ],
      "metadata": {
        "id": "S37tReOSMq80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdfbbc54-5d92-48bd-b9bc-c3095bd7201b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859,)\n",
            "X_test shape =  (3369,)\n",
            "Y_train shape =  (7859,)\n",
            "Y_test shape =  (3369,)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pWrke2Bm3f6",
        "outputId": "08e0587a-bfff-46df-a805-4d2e3de5507e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# statistics on how many articles per category in the train DB\n",
        "# numpy unique is useful in this case\n",
        "print('\\n== TRAIN DATA CONTENT INFO ==')\n",
        "unique, counts = np.unique(Y_train, return_counts = True)\n",
        "for i in range(len(unique)):\n",
        "  print(unique[i], labels[i], \"=\", counts[i])"
      ],
      "metadata": {
        "id": "kwKoV3cdMyhl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d3a4530-1e17-4e5b-804f-cb128cc92017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== TRAIN DATA CONTENT INFO ==\n",
            "0 cocoa = 50\n",
            "1 grain = 378\n",
            "2 veg-oil = 66\n",
            "3 earn = 2769\n",
            "4 acq = 1701\n",
            "5 wheat = 14\n",
            "6 copper = 39\n",
            "7 housing = 15\n",
            "8 money-supply = 126\n",
            "9 coffee = 93\n",
            "10 sugar = 114\n",
            "11 trade = 337\n",
            "12 reserves = 40\n",
            "13 ship = 149\n",
            "14 cotton = 18\n",
            "15 carcass = 19\n",
            "16 crude = 387\n",
            "17 nat-gas = 33\n",
            "18 cpi = 59\n",
            "19 money-fx = 475\n",
            "20 interest = 238\n",
            "21 gnp = 91\n",
            "22 meal-feed = 10\n",
            "23 alum = 36\n",
            "24 oilseed = 56\n",
            "25 gold = 77\n",
            "26 tin = 18\n",
            "27 strategic-metal = 13\n",
            "28 livestock = 43\n",
            "29 retail = 19\n",
            "30 ipi = 38\n",
            "31 iron-steel = 34\n",
            "32 rubber = 30\n",
            "33 heat = 9\n",
            "34 jobs = 43\n",
            "35 lei = 10\n",
            "36 bop = 46\n",
            "37 zinc = 17\n",
            "38 orange = 16\n",
            "39 pet- chem = 20\n",
            "40 dlr = 32\n",
            "41 gas = 28\n",
            "42 silver = 10\n",
            "43 wpi = 19\n",
            "44 hog = 10\n",
            "45 lead = 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gaL6dV50M7J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# my_array = [1, 1, 2, 2, 2, 3]\n",
        "# unique, count = np.unique(my_array, return_counts = True)\n",
        "\n",
        "# # print the result\n",
        "# print(unique)\n",
        "# print(count)"
      ],
      "metadata": {
        "id": "dk48PHbRM4Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique, count = np.unique(Y_train, return_counts=True)\n",
        "print(Y_train)    # 7859\n",
        "print(unique)     # Category\n",
        "print(count)      # records per category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjtNNu1WnXfs",
        "outputId": "f13d96d7-9afd-4937-bdfb-38f7ac8d58c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  4  3 ...  4 16  3]\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45]\n",
            "[  50  378   66 2769 1701   14   39   15  126   93  114  337   40  149\n",
            "   18   19  387   33   59  475  238   91   10   36   56   77   18   13\n",
            "   43   19   38   34   30    9   43   10   46   17   16   20   32   28\n",
            "   10   19   10   14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show the same statistics visually\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.figure(1)\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.hist(Y_train, bins='auto')\n",
        "plt.xlabel(\"카테고리\")\n",
        "plt.ylabel(\"Number of occurrences\")\n",
        "plt.title(\"Train data\")\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.hist(Y_test, bins='auto')\n",
        "plt.xlabel(\"카테고리\")\n",
        "plt.ylabel(\"Number of occurrences\")\n",
        "plt.title(\"Test data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-nV-bI_mNExt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "e426c3c3-5a22-459c-ca6a-36dd4eae52be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample data in its raw format\n",
        "print('\\n== SAMPLE ARTICLE (RAW) ==')\n",
        "print(\"article #\", MY_SAMPLE)\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])\n",
        "print(\"number of words\", len(X_train[MY_SAMPLE]))\n",
        "print(X_train[MY_SAMPLE])\n",
        "\n",
        "# python dictionary: word -> index\n",
        "# zero index is not used\n",
        "word_to_id = reuters.get_word_index()\n",
        "print('\\n== DICTIONARY INFO ==')\n",
        "print(\"There are\", len(word_to_id) + 1, \"words in the dictionary.\")\n",
        "print('The index of \"the\" is', word_to_id['the'])"
      ],
      "metadata": {
        "id": "NCct_CMPNIXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e5e8f4-a1cd-4126-a05c-8839d6fa6837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (RAW) ==\n",
            "article # 2947\n",
            "category 4 acq\n",
            "number of words 61\n",
            "[1, 2, 1229, 81, 8, 16, 515, 25, 270, 5, 4, 2, 1229, 111, 267, 7, 73, 2, 2, 7, 108, 13, 80, 1448, 28, 365, 12, 11, 15, 1986, 2, 69, 158, 18, 1296, 1275, 7, 2, 1627, 2, 2, 4, 393, 374, 1229, 323, 5, 2, 1229, 7, 2, 9, 25, 2, 473, 936, 4, 49, 8, 17, 12]\n",
            "\n",
            "== DICTIONARY INFO ==\n",
            "There are 30980 words in the dictionary.\n",
            "The index of \"the\" is 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python dictionary: index -> word\n",
        "# this is the opposite to word_to_id dictionary\n",
        "id_to_word = {}\n",
        "for key, value in word_to_id.items():\n",
        "  id_to_word[value] = key"
      ],
      "metadata": {
        "id": "fwaJEa8GNT4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to translate the sample review\n",
        "# we use python dictionary get() function\n",
        "# it returns \"???\" if the ID is not found\n",
        "# index is subtracted by 3 to handle first 3 special characters\n",
        "#   index 0 is for padding (= filling empty space)\n",
        "#   index 1 is for indicating the beginning of a review\n",
        "#   index 2 is for dropped word (= out of bound)\n",
        "# we use python list and join() function to concatenate the words"
      ],
      "metadata": {
        "id": "fH2_oAl6NXW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoding():\n",
        "  decoded = []\n",
        "  for i in X_train[MY_SAMPLE]:\n",
        "    word = id_to_word.get(i - 3, \"???\")\n",
        "    decoded.append(word)\n",
        "\n",
        "  print('\\n== SAMPLE ARTICLE (DECODED) ==')\n",
        "  print(\" \".join(decoded))\n",
        "  \n",
        "decoding()\n",
        "print(\"category\", Y_train[MY_SAMPLE], labels[Y_train[MY_SAMPLE]])"
      ],
      "metadata": {
        "id": "meJ0vAPXNhAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a2419f-4fd6-4669-d025-febad3dc2ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (DECODED) ==\n",
            "??? ??? telephone corp said it completed its acquisition of the ??? telephone co based in new ??? ??? in exchange for stock valued at 26 3 mln dlrs enterprises ??? about 16 000 access lines in ??? county ??? ??? the third operating telephone subsidiary of ??? telephone in ??? and its ??? largest overall the company said reuter 3\n",
            "category 4 acq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will NOT do padding (as in movie review classification)\n",
        "# instead we will do tokenization for the inputs\n",
        "# we get a numpy array of size MY_NUM_WORDS for each input \n",
        "# the entries are integer counts \n",
        "# the resulting matrix is very big\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "# for i in range(10):\n",
        "#   print(len(X_train[i]))\n",
        "\n",
        "Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "\n",
        "print('before:', X_train[0])\n",
        "print('number before:', len(X_train[0]))\n",
        "X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "print('after:', X_train[0])\n",
        "print('number after:', len(X_train[0]))\n",
        "\n",
        "X_test = Tok.sequences_to_matrix(X_test, mode = 'count')"
      ],
      "metadata": {
        "id": "21DXQk4-Nt0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "885351c6-973c-429b-be4d-34ad8512fa05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before: [1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 2, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 2, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
            "number before: 87\n",
            "after: [0. 1. 4. ... 0. 0. 0.]\n",
            "number after: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tok = Tokenizer(num_words = MY_NUM_WORDS)\n",
        "# X_train = Tok.sequences_to_matrix(X_train, mode = 'count')\n",
        "# X_test = Tok.sequences_to_matrix(X_test, mode = 'count’)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (TOKENIZED INPUT) ==')\n",
        "sample = X_train[MY_SAMPLE]\n",
        "print(*sample, sep = ' ')\n",
        "print(\"Array size:\", len(sample))\n",
        "print(\"Sum of entries:\", np.sum(sample))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6IvUSlAuxkw",
        "outputId": "9714542d-d34b-4247-f048-cb2e6b72efdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (TOKENIZED INPUT) ==\n",
            "0.0 1.0 11.0 0.0 3.0 2.0 0.0 4.0 2.0 1.0 0.0 1.0 2.0 1.0 0.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 2.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 4.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "Array size: 2000\n",
            "Sum of entries: 61.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output reshaping using one-hot encoding\n",
        "# from keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train, NUM_CLASS)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASS)\n",
        "\n",
        "print('\\n== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==')\n",
        "sample = Y_train[MY_SAMPLE]\n",
        "print(sample)\n",
        "print(\"Array size:\", len(sample))\n",
        "\n",
        "show_shape()\n"
      ],
      "metadata": {
        "id": "sOnatkWcN8Z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b760cc27-5560-48bf-cb59-d73db610103f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE ARTICLE (1-HOT ENCODING OUTPUT) ==\n",
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Array size: 46\n",
            "\n",
            "== DB SHAPE INFO ==\n",
            "X_train shape =  (7859, 2000)\n",
            "X_test shape =  (3369, 2000)\n",
            "Y_train shape =  (7859, 46)\n",
            "Y_test shape =  (3369, 46)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "# MODEL BUILDING AND TRAINING #\n",
        "###############################\n",
        "# build a keras sequential model of our DNN\n",
        "# softmax is needed for multi-class classification\n",
        "model = Sequential()\n",
        "model.add(Dense(units=MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))\n",
        "# model.add(Dense(MY_HIDDEN, input_shape = (MY_NUM_WORDS,)))  => have to give Tuple, eg (MY_NUM_WORDS,)\n",
        "model.add(Activation('relu'))       # later comment this out or use others, \n",
        "model.add(Dropout(MY_DROPOUT))\n",
        "model.add(Dense(NUM_CLASS))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xapmZb7pN_ZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646bd193-3ec6-4fbd-bfcf-b1c077c3feda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               1024512   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 46)                23598     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 46)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,048,110\n",
            "Trainable params: 1,048,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction using the model\n",
        "# shape needs to change from (2000,) to (1, 2000)\n",
        "def ask_question():\n",
        "  sample = X_train[MY_SAMPLE]\n",
        "  sample = sample.reshape(1, sample.shape[0])\n",
        "  pred = model.predict(sample, verbose = 0)\n",
        "  guess = np.argmax(pred)\n",
        "  answer = np.argmax(Y_train[MY_SAMPLE])\n",
        "  \n",
        "  print('\\n== SAMPLE QUESTION ==')\n",
        "  print(\"My guess for sample article:\", guess, labels[guess])\n",
        "  print(\"The answer is:\", answer, labels[answer]) \n",
        "  print()\n",
        "\n",
        "ask_question()"
      ],
      "metadata": {
        "id": "_BtHybqwOJYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd579c60-6e33-458e-9a53-9013a556b7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== SAMPLE QUESTION ==\n",
            "My guess for sample article: 1 grain\n",
            "The answer is: 4 acq\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model training and saving\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = MY_EPOCH, batch_size = MY_BATCH, verbose = 1)\n",
        "model.save('chap2.h5')"
      ],
      "metadata": {
        "id": "gXNO6YchOQpM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16f3acb-c43d-4c55-f15d-4ce7a3a1b2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "123/123 [==============================] - 5s 29ms/step - loss: 1.5951 - accuracy: 0.6814 - val_loss: 1.0906 - val_accuracy: 0.7709\n",
            "Epoch 2/10\n",
            "123/123 [==============================] - 3s 27ms/step - loss: 0.8248 - accuracy: 0.8166 - val_loss: 0.9339 - val_accuracy: 0.7964\n",
            "Epoch 3/10\n",
            "123/123 [==============================] - 2s 16ms/step - loss: 0.5725 - accuracy: 0.8693 - val_loss: 0.8737 - val_accuracy: 0.8172\n",
            "Epoch 4/10\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.4284 - accuracy: 0.8997 - val_loss: 0.8846 - val_accuracy: 0.8151\n",
            "Epoch 5/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.3455 - accuracy: 0.9164 - val_loss: 0.8869 - val_accuracy: 0.8172\n",
            "Epoch 6/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2802 - accuracy: 0.9328 - val_loss: 0.9425 - val_accuracy: 0.8035\n",
            "Epoch 7/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2472 - accuracy: 0.9369 - val_loss: 0.9640 - val_accuracy: 0.8071\n",
            "Epoch 8/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2291 - accuracy: 0.9429 - val_loss: 0.9888 - val_accuracy: 0.8115\n",
            "Epoch 9/10\n",
            "123/123 [==============================] - 2s 14ms/step - loss: 0.2129 - accuracy: 0.9457 - val_loss: 1.0073 - val_accuracy: 0.8065\n",
            "Epoch 10/10\n",
            "123/123 [==============================] - 2s 15ms/step - loss: 0.1994 - accuracy: 0.9508 - val_loss: 1.0228 - val_accuracy: 0.8109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# MODEL EVALUATION #\n",
        "####################\n",
        "# evaluate the model and calculate loss and accuracy\n",
        "score = model.evaluate(X_test, Y_test, verbose = 1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "pred = model.predict(X_test)\n",
        "print('Prediction for the first news: ', pred[0])\n",
        "print(np.argmax(pred[0])) \n",
        "print('Answer: ', Y_test[0])\n",
        "print(labels[np.argmax(Y_test[0])]) \n",
        "\n",
        "\n",
        "# ask_question()"
      ],
      "metadata": {
        "id": "A6jJWOAwObWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2124249b-e9ec-433e-af0f-94896fc16e4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106/106 [==============================] - 1s 6ms/step - loss: 1.0228 - accuracy: 0.8109\n",
            "Test loss: 1.022796630859375\n",
            "Test accuracy: 0.8109230995178223\n",
            "Prediction for the first news:  [3.22900496e-06 1.41694851e-04 1.13677243e-05 9.97722089e-01\n",
            " 1.53637506e-04 1.42586930e-06 2.01378793e-06 9.34992477e-06\n",
            " 1.30355897e-04 1.86532270e-05 6.99617885e-05 1.09929169e-04\n",
            " 1.29409556e-04 1.09581044e-04 5.39884695e-06 1.07686526e-06\n",
            " 4.89228754e-04 6.94056507e-06 1.18522366e-05 3.15230456e-04\n",
            " 2.58561951e-04 8.92716998e-05 4.48833407e-06 3.36628386e-06\n",
            " 3.00458578e-05 7.71187570e-06 7.15408021e-07 2.67980369e-07\n",
            " 6.73027353e-06 1.74658499e-06 3.38306963e-05 1.38831956e-06\n",
            " 4.54773544e-05 1.93201254e-06 1.01185724e-05 3.21419435e-07\n",
            " 1.82864424e-05 2.13436397e-06 1.88927006e-05 8.74327100e-07\n",
            " 9.56531858e-06 4.34908907e-06 1.16170031e-06 4.18211903e-06\n",
            " 2.18518622e-07 1.92102038e-06]\n",
            "3\n",
            "Answer:  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "earn\n"
          ]
        }
      ]
    }
  ]
}